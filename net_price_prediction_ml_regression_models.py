# -*- coding: utf-8 -*-
"""Net_Price_Prediction_ML_Regression_Models.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GxkC-XATajTOWwmklAaFOsGKSsXQh5pS

# Regression Model

### Regression models are a class of statistical models used to predict a continuous target variable based on one or more predictor variables.

### Import Spark SQL and Spark ML Libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# from pyspark.ml.feature import VectorAssembler

from pyspark.sql.functions import mean, col, when

from pyspark.ml.regression import RandomForestRegressor,GBTRegressor, DecisionTreeRegressor, LinearRegression
from pyspark.sql.functions import *
from pyspark.ml.feature import *
from pyspark.ml import *
from pyspark.ml.evaluation import *
from pyspark.mllib.evaluation import *
from pyspark.sql.types import *
from pyspark.ml.tuning import ParamGridBuilder, CrossValidator,TrainValidationSplit

from pyspark.context import SparkContext
from pyspark.sql.session import SparkSession

import time

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
IS_SPARK_SUBMIT_CLI = False
if IS_SPARK_SUBMIT_CLI:
    sc = SparkContext.getOrCreate()
    spark = SparkSession(sc)

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Limit the log
spark.sparkContext.setLogLevel("WARN")

"""### Loading data from a CSV file into a Spark DataFrame."""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# File location and type
file_location = "/user/aporwal/Project/export.csv"
file_type = "csv"

# CSV options
infer_schema = "true"
first_row_is_header = "true"
delimiter = ","

# The applied options are for CSV files. For other file types, these will be ignored.
df = spark.read.format(file_type) \
  .option("inferSchema", infer_schema) \
  .option("header", first_row_is_header) \
  .option("sep", delimiter) \
  .load(file_location)

df.show(10)

"""### Performing data cleaning and preprocessing tasks such as handling missing values, casting data types, and creating new features."""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

from pyspark.sql.functions import col, when

columns = ['UNITID','INSTNM','STABBR' , 'LOCALE', 'CONTROL', 'HBCU', 'PBI',
           'ANNHI', 'TRIBAL', 'AANAPII', 'HSI', 'NANTI','SATVRMID', 'SATMTMID' ,'ACTCMMID', 'ACTENMID',
           'ACTMTMID'  , 'SAT_AVG','SAT_AVG_ALL'  , 'MD_EARN_WNE_P10' , 'GT_25K_P6' , 'GRAD_DEBT_MDN_SUPP'
            , 'RPY_3YR_RT_SUPP', 'NPT4_PUB', 'NPT4_PRIV','COSTT4_A','UGDS','TUITIONFEE_IN','TUITIONFEE_OUT','PCTPELL','LPSTAFFORD_CNT','LPSTAFFORD_AMT','LPPPLUS_CNT','LPPPLUS_AMT','BOOKSUPPLY','ROOMBOARD_ON','OTHEREXPENSE_ON','ROOMBOARD_OFF','OTHEREXPENSE_OFF','OTHEREXPENSE_FAM','ENDOWBEGIN','ENDOWEND','ADM_RATE','ENRL_ORIG_YR2_RT','AGE_ENTRY' ,'UGDS_MEN','UGDS_WOMEN']

# Create a new DataFrame dfp with selected columns
dfp = df.select(*columns)

#Casting values to float
dfp = dfp.withColumn('NPT4_PUB', col('NPT4_PUB').cast("float"))
dfp = dfp.withColumn('NPT4_PRIV', col('NPT4_PRIV').cast("float"))

# Fill missing values with 0 for NPT4_PUB and NPT4_PRIV columns
dfp = dfp.withColumn('NPT4_PUB', when(col('NPT4_PUB').isNull(), 0).otherwise(col('NPT4_PUB')))
dfp = dfp.withColumn('NPT4_PRIV', when(col('NPT4_PRIV').isNull(), 0).otherwise(col('NPT4_PRIV')))

# Calculate Net_Price by summing NPT4_PUB and NPT4_PRIV
dfp = dfp.withColumn('Net_Price', col('NPT4_PUB') + col('NPT4_PRIV'))

# Remove outliers and replace with NaN
dfp = dfp.withColumn('Net_Price', when((col('Net_Price') < 1) | (col('Net_Price') > 55000), None).otherwise(col('Net_Price')))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

#Data cleaning

# Drop rows containing null values
dfp = dfp.na.drop()

#Drop unwanted columns since we have calculated Net_price
dfp = dfp.drop('NPT4_PUB', 'NPT4_PRIV')

#remove "PrivacySupressed" values and replace it with null

clean_columns = ['MD_EARN_WNE_P10', 'GT_25K_P6', 'GRAD_DEBT_MDN_SUPP','RPY_3YR_RT_SUPP','LPSTAFFORD_CNT','LPSTAFFORD_AMT','LPPPLUS_CNT','LPPPLUS_AMT','ADM_RATE','ENRL_ORIG_YR2_RT','AGE_ENTRY','UGDS_MEN','UGDS_WOMEN']

for column in clean_columns:
    dfp = dfp.withColumn(column, when(dfp[column].isin(['PrivacySuppressed']), None).otherwise(dfp[column].cast("float")))

# Show the updated DataFrame
dfp.show(2)

"""### Feature Engineering to create new columns as features

"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
'''
Feature engineering , Create a new column represent the SAT score and drop the columns ( 'SATVRMID' , 'SATMTMID')
Feature engineering , Create a new column represent the Average SAT score and drop the columns ( 'SAT_AVG' , 'SAT_AVG_ALL')
Feature engineering , Create a new column represent the ACT score and drop the columns ( 'ACTCMMID' , 'ACTENMID' , 'ACTMTMID')
'''
#SAT_Score
dfp = dfp.withColumn('SATVRMID', col('SATVRMID').cast("float"))
dfp = dfp.withColumn('SATMTMID', col('SATMTMID').cast("float"))
dfp = dfp.withColumn('SATVRMID', when(col('SATVRMID').isNull(), 0).otherwise(col('SATVRMID')))
dfp = dfp.withColumn('SATMTMID', when(col('SATMTMID').isNull(), 0).otherwise(col('SATMTMID')))
dfp = dfp.withColumn('SAT_Score', col('SATVRMID') + col('SATMTMID'))

#Average_SAT
dfp = dfp.withColumn('SAT_AVG', col('SAT_AVG').cast("float"))
dfp = dfp.withColumn('SAT_AVG_ALL', col('SAT_AVG_ALL').cast("float"))
dfp = dfp.withColumn('SAT_AVG', when(col('SAT_AVG').isNull(), 0).otherwise(col('SAT_AVG')))
dfp = dfp.withColumn('SAT_AVG_ALL', when(col('SAT_AVG_ALL').isNull(), 0).otherwise(col('SAT_AVG_ALL')))
dfp = dfp.withColumn('Average_SAT', col('SAT_AVG') + col('SAT_AVG_ALL'))

#ACT_Score
dfp = dfp.withColumn('ACTCMMID', col('ACTCMMID').cast("float"))
dfp = dfp.withColumn('ACTENMID', col('ACTENMID').cast("float"))
dfp = dfp.withColumn('ACTMTMID', col('ACTMTMID').cast("float"))
dfp = dfp.withColumn('ACTCMMID', when(col('ACTCMMID').isNull(), 0).otherwise(col('ACTCMMID')))
dfp = dfp.withColumn('ACTENMID', when(col('ACTENMID').isNull(), 0).otherwise(col('ACTENMID')))
dfp = dfp.withColumn('ACTMTMID', when(col('ACTMTMID').isNull(), 0).otherwise(col('ACTMTMID')))
dfp = dfp.withColumn('ACT_Score', col('ACTCMMID') + col('ACTENMID') + col('ACTMTMID'))


#Check if Earning , Aid and repayment columns are null, if yes, then replace it with the mean value

mean_MD_EARN_WNE_P10 = dfp.select(mean(col("MD_EARN_WNE_P10"))).collect()[0][0]
mean_GT_25K_P6 = dfp.select(mean(col("GT_25K_P6"))).collect()[0][0]
mean_GRAD_DEBT_MDN_SUPP = dfp.select(mean(col("GRAD_DEBT_MDN_SUPP"))).collect()[0][0]
mean_RPY_3YR_RT_SUPP = dfp.select(mean(col("RPY_3YR_RT_SUPP"))).collect()[0][0]

# Replace null values with mean values
dfp = dfp.withColumn("MD_EARN_WNE_P10", when(col("MD_EARN_WNE_P10").isNull(), mean_MD_EARN_WNE_P10).otherwise(col("MD_EARN_WNE_P10")))
dfp = dfp.withColumn("GT_25K_P6", when(col("GT_25K_P6").isNull(), mean_GT_25K_P6).otherwise(col("GT_25K_P6")))
dfp = dfp.withColumn("GRAD_DEBT_MDN_SUPP", when(col("GRAD_DEBT_MDN_SUPP").isNull(), mean_GRAD_DEBT_MDN_SUPP).otherwise(col("GRAD_DEBT_MDN_SUPP")))
dfp = dfp.withColumn("RPY_3YR_RT_SUPP", when(col("RPY_3YR_RT_SUPP").isNull(), mean_RPY_3YR_RT_SUPP).otherwise(col("RPY_3YR_RT_SUPP")))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
#COSTT4_A
dfp = dfp.withColumn('COSTT4_A', col('COSTT4_A').cast("float"))

#UGDS
dfp = dfp.withColumn('UGDS', col('UGDS').cast("float"))

#loan, tuition and expenses
dfp = dfp.withColumn('TUITIONFEE_IN', col('TUITIONFEE_IN').cast("float"))
dfp = dfp.withColumn('TUITIONFEE_OUT', col('TUITIONFEE_OUT').cast("float"))
dfp = dfp.withColumn('PCTPELL', col('PCTPELL').cast("float"))
dfp = dfp.withColumn('LPSTAFFORD_CNT', col('LPSTAFFORD_CNT').cast("float"))
dfp = dfp.withColumn('LPSTAFFORD_AMT', col('LPSTAFFORD_AMT').cast("float"))
dfp = dfp.withColumn('LPPPLUS_CNT', col('LPPPLUS_CNT').cast("float"))
dfp = dfp.withColumn('LPPPLUS_AMT', col('LPPPLUS_AMT').cast("float"))
dfp = dfp.withColumn('BOOKSUPPLY', col('BOOKSUPPLY').cast("float"))
dfp = dfp.withColumn('ROOMBOARD_ON', col('ROOMBOARD_ON').cast("float"))
dfp = dfp.withColumn('OTHEREXPENSE_ON', col('OTHEREXPENSE_ON').cast("float"))
dfp = dfp.withColumn('ROOMBOARD_OFF', col('ROOMBOARD_OFF').cast("float"))
dfp = dfp.withColumn('OTHEREXPENSE_OFF', col('OTHEREXPENSE_OFF').cast("float"))
dfp = dfp.withColumn('OTHEREXPENSE_FAM', col('OTHEREXPENSE_FAM').cast("float"))
dfp = dfp.withColumn('ENDOWBEGIN', col('ENDOWBEGIN').cast("float"))
dfp = dfp.withColumn('ENDOWEND', col('ENDOWEND').cast("float"))

#student demographics, addmission_rate, age, gender

dfp = dfp.withColumn('ADM_RATE', col('ADM_RATE').cast("float"))
dfp = dfp.withColumn('ENRL_ORIG_YR2_RT', col('ENRL_ORIG_YR2_RT').cast("float"))
dfp = dfp.withColumn('AGE_ENTRY', col('AGE_ENTRY').cast("float"))
dfp = dfp.withColumn('UGDS_MEN', col('UGDS_MEN').cast("float"))
dfp = dfp.withColumn('UGDS_WOMEN', col('UGDS_WOMEN').cast("float"))

"""### Calculating mean values and replacing null values with mean values"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
#replace null and 0's with the mean value

mean_COSTT4_A = dfp.select(mean(col("COSTT4_A"))).collect()[0][0]
mean_TUITIONFEE_IN = dfp.select(mean(col("TUITIONFEE_IN"))).collect()[0][0]
mean_TUITIONFEE_OUT = dfp.select(mean(col("TUITIONFEE_OUT"))).collect()[0][0]
mean_PCTPELL = dfp.select(mean(col("PCTPELL"))).collect()[0][0]
mean_LPSTAFFORD_CNT = dfp.select(mean(col("LPSTAFFORD_CNT"))).collect()[0][0]
mean_LPSTAFFORD_AMT = dfp.select(mean(col("LPSTAFFORD_AMT"))).collect()[0][0]
mean_LPPPLUS_CNT = dfp.select(mean(col("LPPPLUS_CNT"))).collect()[0][0]
mean_LPPPLUS_AMT = dfp.select(mean(col("LPPPLUS_AMT"))).collect()[0][0]
mean_BOOKSUPPLY = dfp.select(mean(col("BOOKSUPPLY"))).collect()[0][0]
mean_ROOMBOARD_ON = dfp.select(mean(col("ROOMBOARD_ON"))).collect()[0][0]
mean_OTHEREXPENSE_ON = dfp.select(mean(col("OTHEREXPENSE_ON"))).collect()[0][0]
mean_ROOMBOARD_OFF = dfp.select(mean(col("ROOMBOARD_OFF"))).collect()[0][0]
mean_OTHEREXPENSE_OFF = dfp.select(mean(col("OTHEREXPENSE_OFF"))).collect()[0][0]
mean_OTHEREXPENSE_FAM = dfp.select(mean(col("OTHEREXPENSE_FAM"))).collect()[0][0]
mean_ENDOWBEGIN = dfp.select(mean(col("ENDOWBEGIN"))).collect()[0][0]
mean_ENDOWEND = dfp.select(mean(col("ENDOWEND"))).collect()[0][0]
mean_UGDS = dfp.select(mean(col("UGDS"))).collect()[0][0]
mean_ADM_RATE = dfp.select(mean(col("ADM_RATE"))).collect()[0][0]
mean_ENRL_ORIG_YR2_RT = dfp.select(mean(col("ENRL_ORIG_YR2_RT"))).collect()[0][0]
mean_AGE_ENTRY = dfp.select(mean(col("AGE_ENTRY"))).collect()[0][0]
mean_UGDS_MEN = dfp.select(mean(col("UGDS_MEN"))).collect()[0][0]
mean_UGDS_WOMEN= dfp.select(mean(col("UGDS_WOMEN"))).collect()[0][0]



# Replace null values with mean values
dfp = dfp.withColumn("COSTT4_A", when((col("COSTT4_A").isNull()) | (col("COSTT4_A") == 0.0), mean_COSTT4_A).otherwise(col("COSTT4_A")))
dfp = dfp.withColumn("UGDS", when((col("UGDS").isNull()) | (col("UGDS") == 0.0), mean_UGDS).otherwise(col("UGDS")))
dfp = dfp.withColumn("TUITIONFEE_IN", when((col("TUITIONFEE_IN").isNull()) | (col("TUITIONFEE_IN") == 0.0), mean_TUITIONFEE_IN).otherwise(col("TUITIONFEE_IN")))
dfp = dfp.withColumn("TUITIONFEE_OUT", when((col("TUITIONFEE_OUT").isNull()) | (col("TUITIONFEE_OUT") == 0.0), mean_TUITIONFEE_OUT).otherwise(col("TUITIONFEE_OUT")))
dfp = dfp.withColumn("PCTPELL", when((col("PCTPELL").isNull()) | (col("PCTPELL") == 0.0), mean_PCTPELL).otherwise(col("PCTPELL")))
dfp = dfp.withColumn("LPSTAFFORD_CNT", when((col("LPSTAFFORD_CNT").isNull()) | (col("LPSTAFFORD_CNT") == 0.0), mean_LPSTAFFORD_CNT).otherwise(col("LPSTAFFORD_CNT")))
dfp = dfp.withColumn("LPSTAFFORD_AMT", when((col("LPSTAFFORD_AMT").isNull()) | (col("LPSTAFFORD_AMT") == 0.0), mean_LPSTAFFORD_AMT).otherwise(col("LPSTAFFORD_AMT")))
dfp = dfp.withColumn("LPPPLUS_CNT", when((col("LPPPLUS_CNT").isNull()) | (col("LPPPLUS_CNT") == 0.0), mean_LPPPLUS_CNT).otherwise(col("LPPPLUS_CNT")))
dfp = dfp.withColumn("LPPPLUS_AMT", when((col("LPPPLUS_AMT").isNull()) | (col("LPPPLUS_AMT") == 0.0), mean_LPPPLUS_AMT).otherwise(col("LPPPLUS_AMT")))
dfp = dfp.withColumn("BOOKSUPPLY", when((col("BOOKSUPPLY").isNull()) | (col("BOOKSUPPLY") == 0.0), mean_BOOKSUPPLY).otherwise(col("BOOKSUPPLY")))
dfp = dfp.withColumn("ROOMBOARD_ON", when((col("ROOMBOARD_ON").isNull()) | (col("ROOMBOARD_ON") == 0.0), mean_ROOMBOARD_ON).otherwise(col("ROOMBOARD_ON")))
dfp = dfp.withColumn("OTHEREXPENSE_ON", when((col("OTHEREXPENSE_ON").isNull()) | (col("OTHEREXPENSE_ON") == 0.0), mean_OTHEREXPENSE_ON).otherwise(col("OTHEREXPENSE_ON")))
dfp = dfp.withColumn("ROOMBOARD_OFF", when((col("ROOMBOARD_OFF").isNull()) | (col("ROOMBOARD_OFF") == 0.0), mean_ROOMBOARD_OFF).otherwise(col("ROOMBOARD_OFF")))
dfp = dfp.withColumn("OTHEREXPENSE_OFF", when((col("OTHEREXPENSE_OFF").isNull()) | (col("OTHEREXPENSE_OFF") == 0.0), mean_OTHEREXPENSE_OFF).otherwise(col("OTHEREXPENSE_OFF")))
dfp = dfp.withColumn("OTHEREXPENSE_FAM", when((col("OTHEREXPENSE_FAM").isNull()) | (col("OTHEREXPENSE_FAM") == 0.0), mean_OTHEREXPENSE_FAM).otherwise(col("OTHEREXPENSE_FAM")))
dfp = dfp.withColumn("ENDOWBEGIN", when((col("ENDOWBEGIN").isNull()) | (col("ENDOWBEGIN") == 0.0), mean_ENDOWBEGIN).otherwise(col("ENDOWBEGIN")))
dfp = dfp.withColumn("ENDOWEND", when((col("ENDOWEND").isNull()) | (col("ENDOWEND") == 0.0), mean_ENDOWEND).otherwise(col("ENDOWEND")))
dfp = dfp.withColumn("ADM_RATE", when((col("ADM_RATE").isNull()) | (col("ADM_RATE") == 0.0), mean_ADM_RATE).otherwise(col("ADM_RATE")))
dfp = dfp.withColumn("ENRL_ORIG_YR2_RT", when((col("ENRL_ORIG_YR2_RT").isNull()) | (col("ENRL_ORIG_YR2_RT") == 0.0), mean_ENRL_ORIG_YR2_RT).otherwise(col("ENRL_ORIG_YR2_RT")))
dfp = dfp.withColumn("AGE_ENTRY", when((col("AGE_ENTRY").isNull()) | (col("AGE_ENTRY") == 0.0), mean_AGE_ENTRY).otherwise(col("AGE_ENTRY")))
dfp = dfp.withColumn("UGDS_MEN", when((col("UGDS_MEN").isNull()) | (col("UGDS_MEN") == 0.0), mean_UGDS_MEN).otherwise(col("UGDS_MEN")))
dfp = dfp.withColumn("UGDS_WOMEN", when((col("UGDS_WOMEN").isNull()) | (col("UGDS_WOMEN") == 0.0), mean_UGDS_WOMEN).otherwise(col("UGDS_WOMEN")))

"""### Visualize histograms to identify outliers in the data and then handle them by removing the extreme values"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Finding outliers for SAT_Score
import matplotlib.pyplot as plt

data = dfp.select('SAT_Score').toPandas()

# Plotting a histogram using Matplotlib
plt.hist(data['SAT_Score'], bins=50)
plt.title('Histogram of Values')
plt.xlabel('SAT_Score')
plt.ylabel('count')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Finding outliers for Average_SAT

import matplotlib.pyplot as plt

data = dfp.select('Average_SAT').toPandas()

# Plotting a histogram using Matplotlib
plt.hist(data['Average_SAT'], bins=70)
plt.title('Histogram of Values')
plt.xlabel('Average_SAT')
plt.ylabel('count')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Finding outliers for ACT_Score

import matplotlib.pyplot as plt

data = dfp.select('ACT_Score').toPandas()

# Plotting a histogram using Matplotlib
plt.hist(data['ACT_Score'], bins=80)
plt.title('Histogram of Values')
plt.xlabel('ACT_Score')
plt.ylabel('count')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Finding outliers for COSTT4_A

import matplotlib.pyplot as plt

# Convert PySpark DataFrame to Pandas DataFrame for visualization
df_pd = df.select("COSTT4_A").toPandas()

# Plotting a histogram using Matplotlib
plt.hist(df_pd['COSTT4_A'], bins=50)
plt.title('Histogram of Values')
plt.xlabel('COSTT4_A')
plt.ylabel('count')
plt.show()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Remove outliers and replace with NaN
dfp = dfp.withColumn('SAT_Score', when((col('SAT_Score') < 700) | (col('SAT_Score') > 1550), 0.0).otherwise(col('SAT_Score')))
dfp = dfp.withColumn('Average_SAT', when((col('Average_SAT') < 1500) | (col('Average_SAT') > 3100), 0.0).otherwise(col('Average_SAT')))
dfp = dfp.withColumn('ACT_Score', when((col('ACT_Score') < 40) | (col('ACT_Score') > 110), 0.0).otherwise(col('ACT_Score')))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
#remove Null values converted to '0' for SAT_Score, Average_Score, ACT_Score, Age_Entry
dfp = dfp.filter(dfp["SAT_Score"] != 0.0)
dfp = dfp.filter(dfp["Average_SAT"] != 0.0)
dfp = dfp.filter(dfp["ACT_Score"] != 0.0)
dfp = dfp.filter(dfp["Age_Entry"] != 0.0)

"""### Used StringIndexer to convert categorical features represented as strings into numerical features"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
from pyspark.ml.feature import StringIndexer

indexer = StringIndexer(inputCol="STABBR", outputCol="STABBRIndex")
dfp = indexer.fit(dfp).transform(dfp)

"""### Drop unwanted columns"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
dfp = dfp.drop('SATVRMID', 'SATMTMID' ,'ACTCMMID', 'ACTENMID','ACTMTMID','SAT_AVG','SAT_AVG_ALL')

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
dfp.printSchema()

"""### Creating a temporary table with the clean data"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
temp_table_name = "US_Scorecard"

dfp.createOrReplaceTempView(temp_table_name)

"""### Selecting only the columns that will be used as features"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
''''
removed fields that were null : NANTI, HBCU,PBI,ANNHI,TRIBAL,AANAPII,HSI,GT_25K_P6
'''

dfp_1= dfp.select('STABBRIndex' , 'CONTROL', 'MD_EARN_WNE_P10', 'GRAD_DEBT_MDN_SUPP', 'SAT_Score', 'Average_SAT', 'ACT_Score', 'COSTT4_A','UGDS','TUITIONFEE_IN','TUITIONFEE_OUT','PCTPELL','LPSTAFFORD_CNT','LPSTAFFORD_AMT','LPPPLUS_CNT','LPPPLUS_AMT','BOOKSUPPLY','ROOMBOARD_ON','OTHEREXPENSE_ON','ROOMBOARD_OFF','OTHEREXPENSE_OFF','OTHEREXPENSE_FAM','ENDOWBEGIN','ENDOWEND','ADM_RATE','ENRL_ORIG_YR2_RT','UGDS_MEN','UGDS_WOMEN','AGE_ENTRY', 'RPY_3YR_RT_SUPP', col("Net_Price").alias("label"))

dfp_1.show(2)

"""### Splitting the data into training and testing data sets."""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
splits = dfp_1.randomSplit([0.7,0.3])
train = splits[0]
test = splits[1].withColumnRenamed("label", "trueLabel")

print ("Training Rows:", train.count(), " Testing Rows:", test.count())

"""### Assembler is a feature transformer that combines a given list of columns into a single vector column.
### MinMax scaling method is a data normalization technique that rescales the features of a dataset so that they fall within a specified range, typically between 0 and 1.
### We applied the above two transformer for the data set.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

assembler = VectorAssembler(inputCols = ['STABBRIndex' , 'CONTROL','MD_EARN_WNE_P10', 'GRAD_DEBT_MDN_SUPP','RPY_3YR_RT_SUPP', 'SAT_Score', 'Average_SAT', 'ACT_Score','COSTT4_A','UGDS','TUITIONFEE_IN','TUITIONFEE_OUT','PCTPELL','LPSTAFFORD_CNT','LPSTAFFORD_AMT','LPPPLUS_CNT','LPPPLUS_AMT','BOOKSUPPLY','ROOMBOARD_ON','OTHEREXPENSE_ON','ROOMBOARD_OFF','OTHEREXPENSE_OFF','OTHEREXPENSE_FAM','ENDOWBEGIN','ENDOWEND','ADM_RATE','ENRL_ORIG_YR2_RT','UGDS_MEN','UGDS_WOMEN', 'AGE_ENTRY'], outputCol="features")


minMax = MinMaxScaler(inputCol = assembler.getOutputCol(), outputCol="normFeatures")

"""## Feature importance
### Its a technique that evaluates the significance of different input features in predicting the target variable.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
rf = RandomForestRegressor(labelCol="label", featuresCol="normFeatures" ) #numTrees=10

pipeline0_rf = Pipeline(stages=[assembler, minMax, rf])

model = pipeline0_rf.fit(train)

rfModel = model.stages[-1]
print(rfModel.toDebugString)

import pandas as pd

featureImp = pd.DataFrame(list(zip(assembler.getInputCols(), rfModel.featureImportances)),
columns=["normFeatures", "importance"])
featureImp.sort_values(by="importance", ascending=False)

"""## Random Forest"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
rf = RandomForestRegressor(labelCol="label", featuresCol="normFeatures")

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
model = []
pipeline = []

"""### Parameter Tuning for Train Validation Split"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Train validator parameters

paramGrid = ParamGridBuilder() \
.addGrid(rf.maxDepth, [8, 10]) \
.addGrid(rf.numTrees, [12, 15]) \
.addGrid(rf.minInfoGain, [0.0]) \
.addGrid(rf.maxBins, [58, 60]) \
.build()

# paramGrid = ParamGridBuilder() \
#  .addGrid(rf.maxDepth, [3, 5]) \
#  .addGrid(rf.minInfoGain, [0.0]) \
#  .addGrid(rf.maxBins, [58,60]) \
#  .build()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Start recording time
start_time = time.time()

"""## Training the model using Train-Validation Split and Cross-Validation methods.

### Organized workflow using pipelines, which help in chaining multiple stages of transformations and model training.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

pipeline.insert(0, Pipeline(stages=[assembler, minMax,rf]))

tv = TrainValidationSplit(estimator=pipeline[0], evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)

# the first model
model.insert(0, tv.fit(train))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# End recording time
end_time = time.time()


# Calculate the elapsed time
execution_time = end_time - start_time
print("Random Forest Model execution time with TVS: {:.2f} seconds".format(execution_time))

"""### Parameter Tuning for Cross Validation"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Cross Validator parameters

paramGridCV = ParamGridBuilder() \
    .addGrid(rf.maxDepth, [8, 10]) \
    .addGrid(rf.numTrees, [12, 15]) \
    .addGrid(rf.minInfoGain, [0.0]) \
    .addGrid(rf.maxBins, [58, 60]) \
    .build()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Start recording time
start_time = time.time()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
pipeline.insert(1, Pipeline(stages=[assembler, minMax, rf]))

# K=3, 5
K = 3
cv = CrossValidator(estimator=pipeline[1], evaluator=RegressionEvaluator(), estimatorParamMaps=paramGridCV, numFolds=K)

# the second model
model.insert(1, cv.fit(train))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# End recording time
end_time = time.time()


# Calculate the elapsed time
execution_time = end_time - start_time
print("Random Forest Model execution time with CV: {:.2f} seconds".format(execution_time))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Test the model
# list prediction
prediction = []
predicted = []
i = 0
for i in range(2):
  prediction.insert(i, model[i].transform(test))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Examine the Predicted and Actual Values
i=0
for i in range(2):
  predicted.insert(i, prediction[i].select("normFeatures", "prediction", "trueLabel"))
  predicted[i].show(20)

"""## Retrieve the Root Mean Square Error (RMSE) for Random Forest
## There are a number of metrics used to measure the variance between predicted and actual values. The root mean square error (RMSE) is measured in the same units as the prediced and actual values. Here the RMSE indicates the average difference of netprice between predicted and actual netprice values.
"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Retrieve the Root Mean Square Error (RMSE)
i=0
rmses = []
for i in range(2):
  evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="rmse")
  rmse = evaluator.evaluate(predicted[i])
  rmses.insert(i, rmse)
  print ("Random Forest Model")
  print ("Model ", i, ": ", "Root Mean Square Error (RMSE):", rmses[i])

"""## R2 for RandomForest Regression (RF)
## R2 is reffered as coefficient of determination and statistical measure that indicates how well the independent variable(s) explain the variability of the dependent variable. R2 values range from 0 to 1, where 0 indicates that the independent variable(s) do not explain any of the variability of the dependent variable, and 1 indicates that they explain all of it.

"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Retrieve the R2

i=0
r2s = []
for i in range(2):
  evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="r2")
  r2 = evaluator.evaluate(predicted[i])
  r2s.insert(i, r2)
  print ("Model ", i, ": ", "Coefficient of Determination (R2):", r2s[i])

"""# Checking if Model Overfitted"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Finding if the model is overfitted by checking the results with the train data
prediction = []
predicted = []
i = 0
for i in range(1):
  prediction.insert(i, model[i].transform(train))
i=0
for i in range(1):
  predicted.insert(i, prediction[i].select("normFeatures", "prediction", "label"))

i=0
rmses = []
for i in range(1):
  evaluator = RegressionEvaluator(labelCol="label", predictionCol="prediction", metricName="rmse")
  rmse = evaluator.evaluate(predicted[i])
  rmses.insert(i, rmse)
  print ("RF Model(Train data) ", i, ": ", "Root Mean Square Error (RMSE):", rmses[i])

# Retrieve the R2 for train data

i=0
r2s = []
for i in range(1):
  evaluator = RegressionEvaluator(labelCol="label", predictionCol="prediction", metricName="r2")
  r2 = evaluator.evaluate(predicted[i])
  r2s.insert(i, r2)
  print ("RF Model(Train data) ", i, ": ", "Coefficient of Determination (R2):", r2s[i])

"""## Gradient Boost Trees

"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

gbt = GBTRegressor(labelCol="label", featuresCol="normFeatures")

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
model = []
pipeline = []

"""## Parameter Tuning for Train-Validation split

"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Train Validation Parameters

paramGrid = ParamGridBuilder()\
.addGrid(gbt.maxDepth, [5, 10, 20])\
.addGrid(gbt.maxBins, [52, 55]) \
.addGrid(gbt.maxIter, [10,20,30]) \
.build()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Start recording time
start_time = time.time()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
pipeline.insert(0, Pipeline(stages=[assembler, minMax, gbt]))

tv = TrainValidationSplit(estimator=pipeline[0], evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)

# the first model
model.insert(0, tv.fit(train))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# End recording time
end_time = time.time()


# Calculate the elapsed time
execution_time = end_time - start_time
print("Gradient Boost Trees Model execution time with TVS: {:.2f} seconds".format(execution_time))

"""## Parameter Tuning for Cross Validation"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Cross Validation Parameters

paramGridCV = ParamGridBuilder()\
.addGrid(gbt.maxDepth, [5, 10, 20])\
.addGrid(gbt.maxBins, [52, 55]) \
.addGrid(gbt.maxIter, [10,20,30]) \
.build()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Start recording time
start_time = time.time()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
pipeline.insert(1, Pipeline(stages=[assembler, minMax, gbt]))

# K=3, 5
K = 3
cv = CrossValidator(estimator=pipeline[1], evaluator=RegressionEvaluator(), estimatorParamMaps=paramGridCV, numFolds=K)

# the second model
model.insert(1, cv.fit(train))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# End recording time
end_time = time.time()


# Calculate the elapsed time
execution_time = end_time - start_time
print("Gradient Boost Trees Model execution time with CV: {:.2f} seconds".format(execution_time))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Test the model
# list prediction
prediction = []
predicted = []
i = 0
for i in range(2):
  prediction.insert(i, model[i].transform(test))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Examine the Predicted and Actual Values
i=0
for i in range(2):
  predicted.insert(i, prediction[i].select("normFeatures", "prediction", "trueLabel"))
  predicted[i].show(20)

"""## RMSE for Gradient Boost Trees Model

"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Retrieve the Root Mean Square Error (RMSE)
i=0
rmses = []
for i in range(2):
  evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="rmse")
  rmse = evaluator.evaluate(predicted[i])
  rmses.insert(i, rmse)
  print ("Gradient Boost Trees Model")
  print ("Model ", i, ": ", "Root Mean Square Error (RMSE):", rmses[i])

"""## R2 for Gradient Boost Trees Model"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Retrieve the R2
i=0
r2s = []
for i in range(2):
  evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="r2")
  r2 = evaluator.evaluate(predicted[i])
  r2s.insert(i, r2)
  print ("Model ", i, ": ", "Coefficient of Determination (R2):", r2s[i])

"""## Decision Tree Regression"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
dt = DecisionTreeRegressor(labelCol="label", featuresCol="normFeatures")

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
model = []
pipeline = []

"""## Parameter Tuning Train-Validation split"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Train validator parameters

paramGrid = ParamGridBuilder() \
 .addGrid(dt.maxDepth, [15, 20]) \
 .addGrid(dt.minInfoGain, [0.0]) \
 .addGrid(dt.maxBins, [58,60]) \
 .build()

# paramGrid = ParamGridBuilder() \
#  .addGrid(dt.maxDepth, [5, 10]) \
#  .addGrid(dt.minInfoGain, [0.0]) \
#  .addGrid(dt.maxBins, [58,60]) \
#  .build()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Start recording time
start_time = time.time()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

pipeline.insert(0, Pipeline(stages=[assembler,minMax, dt]))

tv = TrainValidationSplit(estimator=pipeline[0], evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)

# the first model
model.insert(0, tv.fit(train))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# End recording time
end_time = time.time()


# Calculate the elapsed time
execution_time = end_time - start_time
print("Decision Tree Regression Model execution time with TVS: {:.2f} seconds".format(execution_time))

"""## Parameter Tuning for Cross Validation split

"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Cross Validator parameters

paramGridCV = ParamGridBuilder() \
 .addGrid(dt.maxDepth, [15, 20]) \
 .addGrid(dt.minInfoGain, [0.0]) \
 .addGrid(dt.maxBins, [58,60]) \
 .build()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Start recording time
start_time = time.time()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
pipeline.insert(1, Pipeline(stages=[assembler, minMax, dt]))

# K=3, 5
K = 3
cv = CrossValidator(estimator=pipeline[1], evaluator=RegressionEvaluator(), estimatorParamMaps=paramGridCV, numFolds=K)

# the second model
model.insert(1, cv.fit(train))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# End recording time
end_time = time.time()


# Calculate the elapsed time
execution_time = end_time - start_time
print("Decision Tree Regression Model execution time with CV: {:.2f} seconds".format(execution_time))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Test the model
# list prediction
prediction = []
predicted = []
i = 0
for i in range(2):
  prediction.insert(i, model[i].transform(test))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Examine the Predicted and Actual Values
i=0
for i in range(2):
  predicted.insert(i, prediction[i].select("normFeatures", "prediction", "trueLabel"))
  predicted[i].show(20)

"""## RMSE for Decision Tree Regression Model"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Retrieve the Root Mean Square Error (RMSE)
i=0
rmses = []
for i in range(2):
  evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="rmse")
  rmse = evaluator.evaluate(predicted[i])
  rmses.insert(i, rmse)
  print ("Decision Tree Regression Model")
  print ("Model ", i, ": ", "Root Mean Square Error (RMSE):", rmses[i])

"""## R2 for Decision Tree Regression Model

"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Retrieve the R2

i=0
r2s = []
for i in range(2):
  evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="r2")
  r2 = evaluator.evaluate(predicted[i])
  r2s.insert(i, r2)
  print ("Model ", i, ": ", "Coefficient of Determination (R2):", r2s[i])

"""## Linear Regression"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
lr = LinearRegression(labelCol="label", featuresCol="normFeatures")

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
model = []
pipeline = []

"""## Parameter Tuning for Train-Validation split"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Train validator parameters



paramGrid = ParamGridBuilder() \
.addGrid(lr.maxIter, [20,30,40]) \
.addGrid(lr.regParam, [0.01, 0.1, 1.0]) \
.addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \
.addGrid(lr.standardization, [True, False]) \
.build()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Start recording time
start_time = time.time()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

pipeline.insert(0, Pipeline(stages=[assembler, minMax, lr]))

tv = TrainValidationSplit(estimator=pipeline[0], evaluator=RegressionEvaluator(), estimatorParamMaps=paramGrid, trainRatio=0.8)

# the first model
model.insert(0, tv.fit(train))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# End recording time
end_time = time.time()


# Calculate the elapsed time
execution_time = end_time - start_time
print("Linear Regression Model execution time with TVS: {:.2f} seconds".format(execution_time))

"""## Parameter Tuning for Cross Validation"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark

# Cross Validator parameters

paramGridCV = ParamGridBuilder() \
.addGrid(lr.maxIter, [20,30,40]) \
.addGrid(lr.regParam, [0.01, 0.1, 1.0]) \
.addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \
.addGrid(lr.standardization, [True, False]) \
.build()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Start recording time
start_time = time.time()

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
pipeline.insert(1, Pipeline(stages=[assembler, minMax, lr]))

# K=3, 5
K = 3
cv = CrossValidator(estimator=pipeline[1], evaluator=RegressionEvaluator(), estimatorParamMaps=paramGridCV, numFolds=K)

# the second model
model.insert(1, cv.fit(train))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# End recording time
end_time = time.time()


# Calculate the elapsed time
execution_time = end_time - start_time
print("Linear Regression Model execution time with CV: {:.2f} seconds".format(execution_time))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Test the model
# list prediction
prediction = []
predicted = []
i = 0
for i in range(2):
  prediction.insert(i, model[i].transform(test))

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Examine the Predicted and Actual Values
i=0
for i in range(2):
  predicted.insert(i, prediction[i].select("normFeatures", "prediction", "trueLabel"))
  predicted[i].show(20)

"""## RMSE for Linear Regression Model"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Retrieve the Root Mean Square Error (RMSE)
i=0
rmses = []
for i in range(2):
  evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="rmse")
  rmse = evaluator.evaluate(predicted[i])
  rmses.insert(i, rmse)
  print ("Linear Regression Model")
  print ("Model ", i, ": ", "Root Mean Square Error (RMSE):", rmses[i])

"""## R2 for Linear Regression Model"""

# Commented out IPython magic to ensure Python compatibility.
# %pyspark
# Retrieve the R2

i=0
r2s = []
for i in range(2):
  evaluator = RegressionEvaluator(labelCol="trueLabel", predictionCol="prediction", metricName="r2")
  r2 = evaluator.evaluate(predicted[i])
  r2s.insert(i, r2)
  print ("Model ", i, ": ", "Coefficient of Determination (R2):", r2s[i])

"""%pyspark

"""